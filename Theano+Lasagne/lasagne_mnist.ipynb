{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks with Lasagne\n",
    "Lasagne is a Neural Networks library built on top of Theano. However, it does not completely abstracts Theano, just complements it with various ready-to-use functions and utilities. That's why it's important to know the basics of Theano to use Lasagne well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import *\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "\n",
    "#Load the dataset - function defined in helper.py\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_mnist_dataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Recipes\n",
    "#In the end the models will be Theano expressions\n",
    "from lasagne.layers import *\n",
    "from lasagne.nonlinearities import *\n",
    "from lasagne.init import GlorotUniform\n",
    "\n",
    "def build_mlp(input_var=None):\n",
    "    #shape: batchsize, channels, rows, columns\n",
    "    #none: automatically deduced, as in Tensorflow\n",
    "    l_in        = InputLayer(shape=(None, 1, 28, 28), input_var=input_var)\n",
    "    l_in_drop   = DropoutLayer(l_in, p=0.2)\n",
    "    l_hid1      = DenseLayer(l_in_drop, num_units=800, nonlinearity=rectify, W=GlorotUniform())\n",
    "    l_hid1_drop = DropoutLayer(l_hid1, p=0.5)\n",
    "    l_hid2      = DenseLayer(l_hid1_drop, num_units=800, nonlinearity=rectify)\n",
    "    l_hid2_drop = DropoutLayer(l_hid2, p=0.5)\n",
    "    l_out       = DenseLayer(l_hid2_drop, num_units=10, nonlinearity=softmax)\n",
    "    return l_out\n",
    "\n",
    "\n",
    "def build_cnn(input_var=None):\n",
    "    network = InputLayer(shape=(None, 1, 28, 28), input_var=input_var)\n",
    "    network = Conv2DLayer(network, num_filters=32, filter_size=(5,5), nonlinearity=rectify)\n",
    "    \n",
    "    network = MaxPool2DLayer(network, pool_size=(2,2))\n",
    "    network = Conv2DLayer(network, num_filters=32, filter_size=(5,5), nonlinearity=rectify)\n",
    "    network = MaxPool2DLayer(network, pool_size=(2,2))\n",
    "    \n",
    "    #normal MLP\n",
    "    network = DropoutLayer(network, p=.5)\n",
    "    network = DenseLayer(network, num_units=256, nonlinearity=rectify)\n",
    "    network = DropoutLayer(network, p=.5)\n",
    "    network = DenseLayer(network, num_units=10, nonlinearity=softmax)\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create Theano expression with our entry-points\n",
    "input_var = T.tensor4('inputs')\n",
    "target_var = T.ivector('targets')\n",
    "network = build_cnn(input_var) #or build_mlp\n",
    "\n",
    "#loss function\n",
    "prediction = lasagne.layers.get_output(network)\n",
    "loss = lasagne.objectives.categorical_crossentropy(prediction, target_var)\n",
    "loss = loss.mean()\n",
    "\n",
    "#calculate updates using loss function\n",
    "params = lasagne.layers.get_all_params(network, trainable=True)\n",
    "updates = lasagne.updates.nesterov_momentum(loss, params, learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "#compiles train function\n",
    "train_fn = theano.function([input_var, target_var], loss, updates=updates)\n",
    "\n",
    "#test function - deterministic deactivates dropout\n",
    "test_prediction = lasagne.layers.get_output(network, deterministic=True)\n",
    "test_loss = lasagne.objectives.categorical_crossentropy(test_prediction, target_var)\n",
    "test_loss = test_loss.mean()\n",
    "test_acc = T.mean(T.eq(T.argmax(test_prediction, axis=1), target_var))\n",
    "test_fn = theano.function([input_var, target_var], [test_loss, test_acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 :\n",
      "Training Loss:  2.30905365944\n",
      "Validation Loss:  2.30790781975\n",
      "Validation Accuracy:  0.102\n",
      "Epoch  1 :\n",
      "Training Loss:  2.32696914673\n",
      "Validation Loss:  2.30446863174\n",
      "Validation Accuracy:  0.114\n",
      "Epoch  2 :\n",
      "Training Loss:  2.32657933235\n",
      "Validation Loss:  2.30025053024\n",
      "Validation Accuracy:  0.126\n",
      "Epoch  3 :\n",
      "Training Loss:  2.31902146339\n",
      "Validation Loss:  2.29582452774\n",
      "Validation Accuracy:  0.162\n",
      "Epoch  4 :\n",
      "Training Loss:  2.30888128281\n",
      "Validation Loss:  2.29115176201\n",
      "Validation Accuracy:  0.182\n",
      "Epoch  5 :\n",
      "Training Loss:  2.30484938622\n",
      "Validation Loss:  2.28652143478\n",
      "Validation Accuracy:  0.204\n",
      "Epoch  6 :\n",
      "Training Loss:  2.30683994293\n",
      "Validation Loss:  2.28166556358\n",
      "Validation Accuracy:  0.234\n",
      "Epoch  7 :\n",
      "Training Loss:  2.28839802742\n",
      "Validation Loss:  2.2765891552\n",
      "Validation Accuracy:  0.266\n",
      "Epoch  8 :\n",
      "Training Loss:  2.295388937\n",
      "Validation Loss:  2.27217626572\n",
      "Validation Accuracy:  0.29\n",
      "Epoch  9 :\n",
      "Training Loss:  2.28562426567\n",
      "Validation Loss:  2.26732993126\n",
      "Validation Accuracy:  0.318\n",
      "Epoch  10 :\n",
      "Training Loss:  2.29087591171\n",
      "Validation Loss:  2.26243019104\n",
      "Validation Accuracy:  0.352\n",
      "Epoch  11 :\n",
      "Training Loss:  2.27454400063\n",
      "Validation Loss:  2.25736474991\n",
      "Validation Accuracy:  0.398\n",
      "Epoch  12 :\n",
      "Training Loss:  2.27551364899\n",
      "Validation Loss:  2.25232386589\n",
      "Validation Accuracy:  0.42\n",
      "Epoch  13 :\n",
      "Training Loss:  2.26839756966\n",
      "Validation Loss:  2.24751615524\n",
      "Validation Accuracy:  0.442\n",
      "Epoch  14 :\n",
      "Training Loss:  2.26164674759\n",
      "Validation Loss:  2.24241447449\n",
      "Validation Accuracy:  0.464\n",
      "Epoch  15 :\n",
      "Training Loss:  2.25013828278\n",
      "Validation Loss:  2.23626279831\n",
      "Validation Accuracy:  0.478\n",
      "Epoch  16 :\n",
      "Training Loss:  2.24766898155\n",
      "Validation Loss:  2.2300131321\n",
      "Validation Accuracy:  0.49\n",
      "Epoch  17 :\n",
      "Training Loss:  2.24861478806\n",
      "Validation Loss:  2.22320604324\n",
      "Validation Accuracy:  0.516\n",
      "Epoch  18 :\n",
      "Training Loss:  2.24475646019\n",
      "Validation Loss:  2.2154443264\n",
      "Validation Accuracy:  0.534\n",
      "Epoch  19 :\n",
      "Training Loss:  2.23649525642\n",
      "Validation Loss:  2.20693659782\n",
      "Validation Accuracy:  0.546\n",
      "Epoch  20 :\n",
      "Training Loss:  2.23473644257\n",
      "Validation Loss:  2.19729232788\n",
      "Validation Accuracy:  0.566\n",
      "Epoch  21 :\n",
      "Training Loss:  2.23221993446\n",
      "Validation Loss:  2.18731570244\n",
      "Validation Accuracy:  0.578\n",
      "Epoch  22 :\n",
      "Training Loss:  2.21651124954\n",
      "Validation Loss:  2.1757850647\n",
      "Validation Accuracy:  0.596\n",
      "Epoch  23 :\n",
      "Training Loss:  2.20310544968\n",
      "Validation Loss:  2.16273641586\n",
      "Validation Accuracy:  0.618\n",
      "Epoch  24 :\n",
      "Training Loss:  2.19897842407\n",
      "Validation Loss:  2.1489238739\n",
      "Validation Accuracy:  0.644\n",
      "Epoch  25 :\n",
      "Training Loss:  2.17921352386\n",
      "Validation Loss:  2.13353180885\n",
      "Validation Accuracy:  0.664\n",
      "Epoch  26 :\n",
      "Training Loss:  2.17967128754\n",
      "Validation Loss:  2.11558818817\n",
      "Validation Accuracy:  0.678\n",
      "Epoch  27 :\n",
      "Training Loss:  2.16876506805\n",
      "Validation Loss:  2.09616398811\n",
      "Validation Accuracy:  0.696\n",
      "Epoch  28 :\n",
      "Training Loss:  2.13831686974\n",
      "Validation Loss:  2.07439899445\n",
      "Validation Accuracy:  0.71\n",
      "Epoch  29 :\n",
      "Training Loss:  2.143699646\n",
      "Validation Loss:  2.05181837082\n",
      "Validation Accuracy:  0.714\n",
      "Epoch  30 :\n",
      "Training Loss:  2.13577723503\n",
      "Validation Loss:  2.02728676796\n",
      "Validation Accuracy:  0.72\n",
      "Epoch  31 :\n",
      "Training Loss:  2.10439610481\n",
      "Validation Loss:  2.00063753128\n",
      "Validation Accuracy:  0.726\n",
      "Epoch  32 :\n",
      "Training Loss:  2.09104728699\n",
      "Validation Loss:  1.9709829092\n",
      "Validation Accuracy:  0.736\n",
      "Epoch  33 :\n",
      "Training Loss:  2.06984758377\n",
      "Validation Loss:  1.93866479397\n",
      "Validation Accuracy:  0.736\n",
      "Epoch  34 :\n",
      "Training Loss:  2.03825068474\n",
      "Validation Loss:  1.90291023254\n",
      "Validation Accuracy:  0.746\n",
      "Epoch  35 :\n",
      "Training Loss:  2.00988149643\n",
      "Validation Loss:  1.86525177956\n",
      "Validation Accuracy:  0.756\n",
      "Epoch  36 :\n",
      "Training Loss:  2.00546836853\n",
      "Validation Loss:  1.8254083395\n",
      "Validation Accuracy:  0.75\n",
      "Epoch  37 :\n",
      "Training Loss:  2.01424431801\n",
      "Validation Loss:  1.78507328033\n",
      "Validation Accuracy:  0.752\n",
      "Epoch  38 :\n",
      "Training Loss:  1.94248056412\n",
      "Validation Loss:  1.7400380373\n",
      "Validation Accuracy:  0.754\n",
      "Epoch  39 :\n",
      "Training Loss:  1.9818662405\n",
      "Validation Loss:  1.69638764858\n",
      "Validation Accuracy:  0.758\n",
      "Epoch  40 :\n",
      "Training Loss:  1.89947891235\n",
      "Validation Loss:  1.65126693249\n",
      "Validation Accuracy:  0.762\n",
      "Epoch  41 :\n",
      "Training Loss:  1.8518255949\n",
      "Validation Loss:  1.59970569611\n",
      "Validation Accuracy:  0.762\n",
      "Epoch  42 :\n",
      "Training Loss:  1.80387592316\n",
      "Validation Loss:  1.54364895821\n",
      "Validation Accuracy:  0.762\n",
      "Epoch  43 :\n",
      "Training Loss:  1.76742255688\n",
      "Validation Loss:  1.4848382473\n",
      "Validation Accuracy:  0.768\n",
      "Epoch  44 :\n",
      "Training Loss:  1.70634663105\n",
      "Validation Loss:  1.4227874279\n",
      "Validation Accuracy:  0.778\n",
      "Epoch  45 :\n",
      "Training Loss:  1.68151581287\n",
      "Validation Loss:  1.35903310776\n",
      "Validation Accuracy:  0.786\n",
      "Epoch  46 :\n",
      "Training Loss:  1.66230618954\n",
      "Validation Loss:  1.29799044132\n",
      "Validation Accuracy:  0.792\n",
      "Epoch  47 :\n",
      "Training Loss:  1.6154384613\n",
      "Validation Loss:  1.23604595661\n",
      "Validation Accuracy:  0.792\n",
      "Epoch  48 :\n",
      "Training Loss:  1.54669296741\n",
      "Validation Loss:  1.1726411581\n",
      "Validation Accuracy:  0.814\n",
      "Epoch  49 :\n",
      "Training Loss:  1.5860106945\n",
      "Validation Loss:  1.11416387558\n",
      "Validation Accuracy:  0.828\n",
      "Epoch  50 :\n",
      "Training Loss:  1.54264914989\n",
      "Validation Loss:  1.06684398651\n",
      "Validation Accuracy:  0.83\n",
      "Epoch  51 :\n",
      "Training Loss:  1.51896739006\n",
      "Validation Loss:  1.01790988445\n",
      "Validation Accuracy:  0.838\n",
      "Epoch  52 :\n",
      "Training Loss:  1.42818892002\n",
      "Validation Loss:  0.970632910728\n",
      "Validation Accuracy:  0.848\n",
      "Epoch  53 :\n",
      "Training Loss:  1.40125584602\n",
      "Validation Loss:  0.925824940205\n",
      "Validation Accuracy:  0.86\n",
      "Epoch  54 :\n",
      "Training Loss:  1.34772598743\n",
      "Validation Loss:  0.878836810589\n",
      "Validation Accuracy:  0.864\n",
      "Epoch  55 :\n",
      "Training Loss:  1.31554448605\n",
      "Validation Loss:  0.829661369324\n",
      "Validation Accuracy:  0.876\n",
      "Epoch  56 :\n",
      "Training Loss:  1.28540349007\n",
      "Validation Loss:  0.786347746849\n",
      "Validation Accuracy:  0.88\n",
      "Epoch  57 :\n",
      "Training Loss:  1.27246880531\n",
      "Validation Loss:  0.746287107468\n",
      "Validation Accuracy:  0.882\n",
      "Epoch  58 :\n",
      "Training Loss:  1.24068725109\n",
      "Validation Loss:  0.707396864891\n",
      "Validation Accuracy:  0.888\n",
      "Epoch  59 :\n",
      "Training Loss:  1.16595304012\n",
      "Validation Loss:  0.67614710331\n",
      "Validation Accuracy:  0.896\n",
      "Epoch  60 :\n",
      "Training Loss:  1.16966676712\n",
      "Validation Loss:  0.644554078579\n",
      "Validation Accuracy:  0.89\n",
      "Epoch  61 :\n",
      "Training Loss:  1.14507758617\n",
      "Validation Loss:  0.623499035835\n",
      "Validation Accuracy:  0.89\n",
      "Epoch  62 :\n",
      "Training Loss:  1.09014701843\n",
      "Validation Loss:  0.6021463871\n",
      "Validation Accuracy:  0.884\n",
      "Epoch  63 :\n",
      "Training Loss:  1.1849616766\n",
      "Validation Loss:  0.586081683636\n",
      "Validation Accuracy:  0.892\n",
      "Epoch  64 :\n",
      "Training Loss:  1.03408765793\n",
      "Validation Loss:  0.569334983826\n",
      "Validation Accuracy:  0.89\n",
      "Epoch  65 :\n",
      "Training Loss:  1.08833444118\n",
      "Validation Loss:  0.551385760307\n",
      "Validation Accuracy:  0.896\n",
      "Epoch  66 :\n",
      "Training Loss:  1.03382635117\n",
      "Validation Loss:  0.540102541447\n",
      "Validation Accuracy:  0.9\n",
      "Epoch  67 :\n",
      "Training Loss:  0.943557143211\n",
      "Validation Loss:  0.525849759579\n",
      "Validation Accuracy:  0.9\n",
      "Epoch  68 :\n",
      "Training Loss:  1.00524151325\n",
      "Validation Loss:  0.509994447231\n",
      "Validation Accuracy:  0.906\n",
      "Epoch  69 :\n",
      "Training Loss:  1.0327321291\n",
      "Validation Loss:  0.496786147356\n",
      "Validation Accuracy:  0.912\n",
      "Epoch  70 :\n",
      "Training Loss:  0.944088339806\n",
      "Validation Loss:  0.480433493853\n",
      "Validation Accuracy:  0.918\n",
      "Epoch  71 :\n",
      "Training Loss:  0.8989585042\n",
      "Validation Loss:  0.463140070438\n",
      "Validation Accuracy:  0.914\n",
      "Epoch  72 :\n",
      "Training Loss:  0.848525464535\n",
      "Validation Loss:  0.448646128178\n",
      "Validation Accuracy:  0.914\n",
      "Epoch  73 :\n",
      "Training Loss:  0.850359261036\n",
      "Validation Loss:  0.435378551483\n",
      "Validation Accuracy:  0.916\n",
      "Epoch  74 :\n",
      "Training Loss:  0.905675947666\n",
      "Validation Loss:  0.424299806356\n",
      "Validation Accuracy:  0.92\n",
      "Epoch  75 :\n",
      "Training Loss:  0.839012086391\n",
      "Validation Loss:  0.411891102791\n",
      "Validation Accuracy:  0.92\n",
      "Epoch  76 :\n",
      "Training Loss:  0.830184936523\n",
      "Validation Loss:  0.400863468647\n",
      "Validation Accuracy:  0.918\n",
      "Epoch  77 :\n",
      "Training Loss:  0.930657088757\n",
      "Validation Loss:  0.396041929722\n",
      "Validation Accuracy:  0.922\n",
      "Epoch  78 :\n",
      "Training Loss:  0.765762209892\n",
      "Validation Loss:  0.392112880945\n",
      "Validation Accuracy:  0.922\n",
      "Epoch  79 :\n",
      "Training Loss:  0.805033326149\n",
      "Validation Loss:  0.386850714684\n",
      "Validation Accuracy:  0.92\n",
      "Epoch  80 :\n",
      "Training Loss:  0.850893080235\n",
      "Validation Loss:  0.380990684032\n",
      "Validation Accuracy:  0.92\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  81 :\n",
      "Training Loss:  0.702403187752\n",
      "Validation Loss:  0.371247559786\n",
      "Validation Accuracy:  0.92\n",
      "Epoch  82 :\n",
      "Training Loss:  0.752934813499\n",
      "Validation Loss:  0.362587720156\n",
      "Validation Accuracy:  0.924\n",
      "Epoch  83 :\n",
      "Training Loss:  0.839942574501\n",
      "Validation Loss:  0.355888426304\n",
      "Validation Accuracy:  0.928\n",
      "Epoch  84 :\n",
      "Training Loss:  0.718110203743\n",
      "Validation Loss:  0.347499042749\n",
      "Validation Accuracy:  0.932\n",
      "Epoch  85 :\n",
      "Training Loss:  0.836731314659\n",
      "Validation Loss:  0.344855219126\n",
      "Validation Accuracy:  0.934\n",
      "Epoch  86 :\n",
      "Training Loss:  0.703250110149\n",
      "Validation Loss:  0.34016919136\n",
      "Validation Accuracy:  0.938\n",
      "Epoch  87 :\n",
      "Training Loss:  0.689890623093\n",
      "Validation Loss:  0.334901303053\n",
      "Validation Accuracy:  0.94\n",
      "Epoch  88 :\n",
      "Training Loss:  0.676585733891\n",
      "Validation Loss:  0.327564448118\n",
      "Validation Accuracy:  0.942\n",
      "Epoch  89 :\n",
      "Training Loss:  0.673731565475\n",
      "Validation Loss:  0.321805000305\n",
      "Validation Accuracy:  0.938\n",
      "Epoch  90 :\n",
      "Training Loss:  0.811765134335\n",
      "Validation Loss:  0.318927109241\n",
      "Validation Accuracy:  0.94\n",
      "Epoch  91 :\n",
      "Training Loss:  0.684283196926\n",
      "Validation Loss:  0.312208741903\n",
      "Validation Accuracy:  0.94\n",
      "Epoch  92 :\n",
      "Training Loss:  0.638839125633\n",
      "Validation Loss:  0.306155860424\n",
      "Validation Accuracy:  0.942\n",
      "Epoch  93 :\n",
      "Training Loss:  0.679253160954\n",
      "Validation Loss:  0.301113039255\n",
      "Validation Accuracy:  0.944\n",
      "Epoch  94 :\n",
      "Training Loss:  0.679184734821\n",
      "Validation Loss:  0.299655586481\n",
      "Validation Accuracy:  0.946\n",
      "Epoch  95 :\n",
      "Training Loss:  0.639028906822\n",
      "Validation Loss:  0.29561701417\n",
      "Validation Accuracy:  0.946\n",
      "Epoch  96 :\n",
      "Training Loss:  0.625213384628\n",
      "Validation Loss:  0.289499819279\n",
      "Validation Accuracy:  0.946\n",
      "Epoch  97 :\n",
      "Training Loss:  0.657852053642\n",
      "Validation Loss:  0.285602241755\n",
      "Validation Accuracy:  0.948\n",
      "Epoch  98 :\n",
      "Training Loss:  0.650240123272\n",
      "Validation Loss:  0.282700866461\n",
      "Validation Accuracy:  0.952\n",
      "Epoch  99 :\n",
      "Training Loss:  0.66191637516\n",
      "Validation Loss:  0.281495064497\n",
      "Validation Accuracy:  0.95\n"
     ]
    }
   ],
   "source": [
    "#Training loop\n",
    "#iterate_minibatches is defined in helper.py\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    train_err = 0\n",
    "    train_batches = 0\n",
    "    for batch in iterate_minibatches(X_train, y_train, 500, shuffle=True):\n",
    "        inputs, targets = batch\n",
    "        train_err += train_fn(inputs, targets)\n",
    "        train_batches += 1\n",
    "    \n",
    "    train_err = train_err / train_batches\n",
    "    \n",
    "    #End of epoch, we show the results so far\n",
    "    val_err = 0\n",
    "    val_acc = 0\n",
    "    val_batches = 0\n",
    "    for batch in iterate_minibatches(X_val, y_val, 500, shuffle=False):\n",
    "        inputs, targets = batch\n",
    "        err, acc = test_fn(inputs, targets)\n",
    "        val_err += err\n",
    "        val_acc += acc\n",
    "        val_batches += 1\n",
    "    val_err = val_err / val_batches\n",
    "    val_acc = val_acc / val_batches\n",
    "    \n",
    "    print(\"Epoch \", epoch, \":\")\n",
    "    print(\"Training Loss: \", train_err)\n",
    "    print(\"Validation Loss: \", val_err)\n",
    "    print(\"Validation Accuracy: \", val_acc)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
